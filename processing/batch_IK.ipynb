{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames: 3085 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_CB_F.trc\n",
      "Number of frames: 3101 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T3_AS_S.trc\n",
      "Number of frames: 3088 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_AS_N.trc\n",
      "Number of frames: 3081 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_OR_M.trc\n",
      "Number of frames: 3079 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_EF_S.trc\n",
      "Number of frames: 3075 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_EF_N.trc\n",
      "Number of frames: 3076 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_EF_F.trc\n",
      "Number of frames: 3093 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T2_ER_S.trc\n",
      "Number of frames: 3092 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_ER_N.trc\n",
      "Number of frames: 3069 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_ER_F.trc\n",
      "Number of frames: 3116 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_CB_S.trc\n",
      "Number of frames: 3063 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_CB_N.trc\n",
      "Number of frames: 3077 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_AS_F.trc\n",
      "Number of frames: 3083 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_AS_VF.trc\n",
      "Number of frames: 3101 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_OR_90.trc\n",
      "Number of frames: 3108 for file: g:\\My Drive\\sd_datacollection_v4\\P02\\raw_marker\\P02_T1_OR_180.trc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trials sequentially: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file: g:\\My Drive\\sd_datacollection_v4\\P02\\processed_joint_kinematics\\P02_T1_CB_F.mot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trials sequentially: 1it [05:01, 301.67s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import re\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os.path as osp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def extract_time_range_from_trc(trc_file):\n",
    "    with open(trc_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    num_frames = int(lines[2].strip().split()[2])\n",
    "    print(f\"Number of frames: {num_frames} for file: {trc_file}\")\n",
    "    data_rate = float(lines[2].strip().split()[0])\n",
    "    time_end = num_frames / data_rate\n",
    "    return (0, time_end)\n",
    "\n",
    "def create_ik_setup_file(template_path, trc_file, output_motion_file, ik_setup_file):\n",
    "    tree = ET.parse(template_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    time_range = extract_time_range_from_trc(trc_file)\n",
    "    time_range_str = f\"{time_range[0]} {time_range[1]}\"\n",
    "\n",
    "    time_range_element = root.find('.//time_range')\n",
    "    time_range_element.text = time_range_str\n",
    "\n",
    "    marker_file = root.find('.//marker_file')\n",
    "    marker_file.text = trc_file\n",
    "\n",
    "    output_motion = root.find('.//output_motion_file')\n",
    "    output_motion.text = output_motion_file\n",
    "\n",
    "    tree.write(ik_setup_file)\n",
    "\n",
    "def clear_file(file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.truncate(0)\n",
    "\n",
    "def run_inverse_kinematics(scaled_model_file, trc_file, ik_setup_file, output_dir):\n",
    "    import opensim as osim\n",
    "\n",
    "    log_file = os.path.join(output_dir, os.path.basename(trc_file).replace('.trc', '_ik.log'))\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(scaled_model_file):\n",
    "            raise FileNotFoundError(f\"Scaled model file not found: {scaled_model_file}\")\n",
    "        if not os.path.exists(trc_file):\n",
    "            raise FileNotFoundError(f\"TRC file not found: {trc_file}\")\n",
    "        if not os.path.exists(ik_setup_file):\n",
    "            raise FileNotFoundError(f\"IK setup file not found: {ik_setup_file}\")\n",
    "\n",
    "        output_file = os.path.join(output_dir, os.path.basename(trc_file).replace('.trc', '.mot'))\n",
    "\n",
    "        print(f\"Output file: {output_file}\")\n",
    "        if os.path.exists(output_file):\n",
    "            logging.info(f\"Output file already exists, skipping: {output_file}\")\n",
    "            print(f\"\\033[93mOutput file already exists, skipping: {output_file}\\033[0m\")\n",
    "            return\n",
    "\n",
    "        model = osim.Model(scaled_model_file)\n",
    "        ik_tool = osim.InverseKinematicsTool(ik_setup_file)\n",
    "        ik_tool.setModel(model)\n",
    "        ik_tool.setMarkerDataFileName(trc_file)\n",
    "        ik_tool.setOutputMotionFileName(output_file)\n",
    "\n",
    "        logging.debug(f\"Running IK Tool with model: {scaled_model_file}, TRC: {trc_file}, Setup: {ik_setup_file}, Output: {output_file}\")\n",
    "\n",
    "        ik_tool.run()\n",
    "\n",
    "        if os.path.exists('./opensim.log'):\n",
    "            shutil.copy2('./opensim.log', log_file)\n",
    "            clear_file('./opensim.log')\n",
    "\n",
    "        print(f\"\\033[92mProcessed {trc_file} successfully\\033[0m\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91mError processing {trc_file}: {e}\\033[0m\")\n",
    "\n",
    "def process_subject_trials(scaled_model_file, trc_files, ik_setup_template, output_dir, parallel=False):\n",
    "    ik_setup_files = []\n",
    "    for trc_file in trc_files:\n",
    "        ik_setup_file = os.path.join(output_dir, os.path.basename(trc_file).replace('.trc', '_ik_setup.xml'))\n",
    "        create_ik_setup_file(ik_setup_template, trc_file, os.path.join(output_dir, os.path.basename(trc_file).replace('.trc', '.mot')), ik_setup_file)\n",
    "        ik_setup_files.append(ik_setup_file)\n",
    "\n",
    "    if parallel:\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(run_inverse_kinematics, scaled_model_file, trc_file, ik_setup_file, output_dir)\n",
    "                for trc_file, ik_setup_file in zip(trc_files, ik_setup_files)\n",
    "            ]\n",
    "            for future in tqdm(futures, desc=\"Processing trials in parallel\"):\n",
    "                future.result()\n",
    "    else:\n",
    "        for trc_file, ik_setup_file in tqdm(zip(trc_files, ik_setup_files)):\n",
    "            tqdm.set_description(f\"Processing: {trc_file} with {scaled_model_file}\")\n",
    "            run_inverse_kinematics(scaled_model_file, trc_file, ik_setup_file, output_dir)\n",
    "\n",
    "def get_log_files_by_subject(base_dir, subjects):\n",
    "    subject_logs = {}\n",
    "    for subject in subjects:\n",
    "        output_dir = os.path.join(base_dir, f'P{str(subject).zfill(2)}', 'processed_joint_kinematics')\n",
    "        if not os.path.exists(output_dir):\n",
    "            print(f\"\\033[91mWarning: Output directory not found for subject {subject}. Skipping.\\033[0m\")\n",
    "            continue\n",
    "        log_files = [\n",
    "            os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('_ik.log')\n",
    "        ]\n",
    "        subject_logs[subject] = log_files\n",
    "    return subject_logs\n",
    "\n",
    "def process_all_subjects(base_dir, subjects, ik_setup_template, parallel=False):\n",
    "    for subject in subjects:\n",
    "        subject_formatted = str(subject).zfill(2)\n",
    "\n",
    "        scaled_model_file = osp.join(base_dir, f'subject_{subject}.osim')\n",
    "        scaled_model_file = osp.expanduser(scaled_model_file)  # Expanded here\n",
    "\n",
    "        trc_files_dir = osp.join(base_dir, f'P{subject_formatted}', 'raw_marker')\n",
    "        trc_files_dir = osp.expanduser(trc_files_dir)  # Expanded here\n",
    "\n",
    "        output_dir = osp.join(base_dir, f'P{subject_formatted}', 'processed_joint_kinematics')\n",
    "        output_dir = osp.expanduser(output_dir)  # Expanded here\n",
    "\n",
    "        if not os.path.exists(trc_files_dir):\n",
    "            print(f\"\\033[91mError: TRC files directory not found: {trc_files_dir}\\033[0m\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        trc_files = [os.path.join(trc_files_dir, f) for f in os.listdir(trc_files_dir) if f.endswith('.trc')]\n",
    "\n",
    "        if not trc_files:\n",
    "            print(f\"\\033[91mError: No TRC files found in directory: {trc_files_dir}\\033[0m\")\n",
    "            continue\n",
    "\n",
    "        process_subject_trials(scaled_model_file, trc_files, ik_setup_template, output_dir, parallel=parallel)\n",
    "\n",
    "        # Plot subject data after processing each subject\n",
    "        subject_logs = get_log_files_by_subject(base_dir, [subject])\n",
    "        if subject_logs:\n",
    "            plot_rms_by_subject(subject_logs)\n",
    "\n",
    "def plot_rms_by_subject(subject_logs):\n",
    "    all_rms_values = []\n",
    "    n_cols = 8\n",
    "\n",
    "    for subject, logs in subject_logs.items():\n",
    "        n_trials = len(logs)\n",
    "        n_rows = (n_trials + n_cols - 1) // n_cols\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(45, 5 * n_rows))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, log_file in enumerate(logs):\n",
    "            rms_values, max_errors = extract_rms_from_log(log_file)\n",
    "            axes[i].plot(rms_values)\n",
    "            axes[i].set_title(os.path.basename(log_file))\n",
    "            axes[i].set_xlabel('Frame')\n",
    "            axes[i].set_ylabel('RMS Error')\n",
    "            axes[i].set_ylim([0, 0.10])\n",
    "            for j, rms in enumerate(rms_values):\n",
    "                if rms > 0.5:\n",
    "                    axes[i].plot(j, rms, 'ro')\n",
    "\n",
    "            all_rms_values.append((os.path.basename(log_file), rms_values))\n",
    "\n",
    "            for marker, errors in max_errors.items():\n",
    "                average_error = sum(errors) / len(errors)\n",
    "                print(f\"File: {os.path.basename(log_file)}, Marker: {marker}, Count: {len(errors)}, Average Error: {average_error:.6f}\")\n",
    "\n",
    "        for i in range(n_trials, n_rows * n_cols):\n",
    "            fig.delaxes(axes[i])\n",
    "\n",
    "        fig.suptitle(f'Subject {subject}')\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.show()\n",
    "\n",
    "def extract_rms_from_log(log_file_path):\n",
    "    rms_values = []\n",
    "    max_errors = defaultdict(list)\n",
    "    with open(log_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if 'marker error: RMS' in line:\n",
    "                rms_match = re.search(r'RMS = ([\\d.]+)', line)\n",
    "                max_match = re.search(r'max = ([\\d.]+) \\((\\w+)\\)', line)\n",
    "                if rms_match and max_match:\n",
    "                    rms_values.append(float(rms_match.group(1)))\n",
    "                    max_error_value = float(max_match.group(1))\n",
    "                    max_error_marker = max_match.group(2)\n",
    "                    max_errors[max_error_marker].append(max_error_value)\n",
    "    return rms_values, max_errors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # base_dir = os.path.expanduser('~/GoogleDrive/sd_datacollection_v4')\n",
    "    # ik_setup_template = os.path.expanduser('~/GoogleDrive/sd_datacollection_v4/default_ik.xml')\n",
    "    \n",
    "    base_dir = os.path.expanduser('g:\\\\My Drive\\\\sd_datacollection_v4')\n",
    "    ik_setup_template = os.path.expanduser('g:\\\\My Drive\\\\sd_datacollection_v4\\\\default_ik.xml')\n",
    "\n",
    "    subjects = [2]\n",
    "\n",
    "    parallel = False  # Set to False to run sequentially\n",
    "    process_all_subjects(base_dir, subjects, ik_setup_template, parallel=parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
